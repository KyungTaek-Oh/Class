{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is PCA?\n",
    "* The PCA Algorithm works by computing principal components where it retains datasets in the **direction of maximum variance** in the original datasets\n",
    "* PCA is a procedure that uses an orthogonal transformation to convert a set of observations possibly correlated variables into a set of values of linearly uncorrelated variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is the step-by-step procedure of PCA?\n",
    "### 1. Perform data pre-processing\n",
    "(e.g. scaling on D-dimensional data)\n",
    "* It is critical to perform normalization prior to implementing the PCA algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute a covariance matrix\n",
    "* This is needed to understand how features are correlated with each other\n",
    "* The covariance matrix is N X N symmetric matrix where N is the # of dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate the eigenvalues and eigenvectors of the covariance matrix\n",
    "* This is needed to determine the **principal components** of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sort the eigenvalue in descending order and find the corresponding eigenvector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Select the largest K cases (**K <= D**) and create a projection matrix (i.e. w) using the cases\n",
    "* K refers to the number of principal components\n",
    "* How to create a projection matrix?\n",
    "  * If K=2, select two corresponding eigenvectors identified by the sorted eigenvalues\n",
    "* How to determine the number of principal components?\n",
    "  * Scree plot: a line plot of the eigenvalues of the eigenvalues of principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Transform data into a lower-dimensional space using the projection matrix\n",
    "* For two principal components, we have:\n",
    "  * Transforming by dot product (normalized data, projection matrix)\n",
    "    * The dot product of the normalized data matrix and the projection matrix effectively projects the original data onto the subspace defined by the principal components.\n",
    "    * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pca(X, num_components=2):\n",
    "    # 1. Regularize the data\n",
    "    mean = np.mean(X, axis=0)\n",
    "    standardized_data = X - mean\n",
    "\n",
    "    # 2. Calculate the covariance matrix\n",
    "    covariance_matrix = np.cov(standardized_data, rowvar=False)\n",
    "\n",
    "    # 3. Calculate the eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "\n",
    "    # 4. Sort eigenvectors in descending order of eigenvalues\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "    # 5. Select the largest 'num_components' eigenvectors\n",
    "    principal_components = eigenvectors[:, :num_components]\n",
    "\n",
    "    # 6. Project the data onto the principal components\n",
    "    transformed_data = np.dot(standardized_data, principal_components)\n",
    "\n",
    "    return transformed_data\n",
    "\n",
    "# Example usage:\n",
    "# Create a sample dataset\n",
    "np.random.seed(42)\n",
    "data = np.random.rand(100, 3)\n",
    "\n",
    "# Apply PCA with 2 components\n",
    "result = pca(data, num_components=2)\n",
    "\n",
    "print(\"Original data shape:\", data.shape)\n",
    "print(\"Transformed data shape:\", result.shape)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
